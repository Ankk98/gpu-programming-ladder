{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Programming Ladder URL Validation System\n",
    "\n",
    "This notebook orchestrates an AI agent system to validate and update URLs in the GPU Programming Ladder data.\n",
    "\n",
    "## Features\n",
    "- **Multi-agent system**: Task creator agent + multiple consumer agents\n",
    "- **URL validation**: Checks if URLs exist and are accessible\n",
    "- **Content analysis**: Ensures exercise/video URLs point to specific content, not listings\n",
    "- **AI-powered replacements**: Uses local LLM (GPT-4o via LM Studio) to find replacements\n",
    "- **Parallel processing**: Configurable concurrent requests with rate limiting\n",
    "- **Thread safety**: No race conditions in concurrent operations\n",
    "\n",
    "## Requirements\n",
    "- Python 3.8+\n",
    "- LM Studio running locally with GPT-4o model\n",
    "- Required Python packages (installed in virtual environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Add current directory to path for imports\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import our custom modules\n",
    "from url_validation_orchestrator import URLValidationOrchestrator\n",
    "from url_extractor import extract_urls_from_data_js\n",
    "from task_creator_agent import TaskCreatorAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure the validation system parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  lm_studio_url: http://localhost:1234\n",
      "  num_consumer_agents: 2\n",
      "  max_concurrent_requests_per_agent: 2\n",
      "  data_js_file: ../data.js\n",
      "  urls_file: urls_to_validate.json\n",
      "  tasks_file: validation_tasks.json\n",
      "  results_file: validation_results.json\n",
      "  update_data_js: True\n",
      "  force_revalidation: False\n"
     ]
    }
   ],
   "source": [
    "# Load configuration from config.json\n",
    "def load_config():\n",
    "    \"\"\"Load configuration from config.json file.\"\"\"\n",
    "    try:\n",
    "        with open(\"config.json\", \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        \n",
    "        # Convert config structure to match notebook expectations\n",
    "        return {\n",
    "            \"lm_studio_url\": config[\"lm_studio\"][\"url\"],\n",
    "            \"num_consumer_agents\": config[\"agents\"][\"num_consumer_agents\"],\n",
    "            \"max_concurrent_requests_per_agent\": config[\"agents\"][\"max_concurrent_requests_per_agent\"],\n",
    "            \"data_js_file\": config[\"files\"][\"data_js\"],\n",
    "            \"urls_file\": config[\"files\"][\"urls_to_validate\"],\n",
    "            \"tasks_file\": config[\"files\"][\"validation_tasks\"],\n",
    "            \"results_file\": config[\"files\"][\"validation_results\"],\n",
    "            \"update_data_js\": config[\"processing\"][\"update_data_js\"],\n",
    "            \"force_revalidation\": config[\"processing\"][\"force_revalidation\"]\n",
    "        }\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå config.json not found. Using default configuration.\")\n",
    "        return {\n",
    "            \"lm_studio_url\": \"http://localhost:1234\",\n",
    "            \"num_consumer_agents\": 2,\n",
    "            \"max_concurrent_requests_per_agent\": 2,\n",
    "            \"data_js_file\": \"../data.js\",\n",
    "            \"urls_file\": \"urls_to_validate.json\",\n",
    "            \"tasks_file\": \"validation_tasks.json\",\n",
    "            \"results_file\": \"validation_results.json\",\n",
    "            \"update_data_js\": True,\n",
    "            \"force_revalidation\": False\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading config.json: {e}. Using default configuration.\")\n",
    "        return {\n",
    "            \"lm_studio_url\": \"http://localhost:1234\",\n",
    "            \"num_consumer_agents\": 2,\n",
    "            \"max_concurrent_requests_per_agent\": 2,\n",
    "            \"data_js_file\": \"../data.js\",\n",
    "            \"urls_file\": \"urls_to_validate.json\",\n",
    "            \"tasks_file\": \"validation_tasks.json\",\n",
    "            \"results_file\": \"validation_results.json\",\n",
    "            \"update_data_js\": True,\n",
    "            \"force_revalidation\": False\n",
    "        }\n",
    "\n",
    "# Load configuration\n",
    "CONFIG = load_config()\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract URLs from data.js\n",
    "\n",
    "First, let's extract all URLs from the data.js file that need validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Extracting URLs from data.js...\n",
      "‚úÖ Extracted 260 URLs\n",
      "\n",
      "üìä URL distribution by type:\n",
      "   article: 62\n",
      "   paper: 26\n",
      "   video: 61\n",
      "   exercise: 65\n",
      "   python: 37\n",
      "   cpp: 9\n",
      "\n",
      "üìã Sample URLs to validate:\n",
      "   1. [article] CPU vs GPU: Why GPUs for ML and HPC...\n",
      "      URL: https://developer.nvidia.com/blog/even-easier-introduction-cuda/\n",
      "   2. [paper] CPU vs GPU: Why GPUs for ML and HPC...\n",
      "      URL: https://dl.acm.org/doi/10.1145/1365490.1365500\n",
      "   3. [video] CPU vs GPU: Why GPUs for ML and HPC...\n",
      "      URL: https://www.youtube.com/watch?v=-P28LKWTzrI\n",
      "   4. [exercise] CPU vs GPU: Why GPUs for ML and HPC...\n",
      "      URL: https://leetgpu.com/challenges\n",
      "   5. [article] GPU Architecture: SMs, warps, cores...\n",
      "      URL: https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/kernel_sm\n"
     ]
    }
   ],
   "source": [
    "# Extract URLs from data.js\n",
    "print(\"üîç Extracting URLs from data.js...\")\n",
    "\n",
    "try:\n",
    "    urls = extract_urls_from_data_js(CONFIG['data_js_file'])\n",
    "    print(f\"‚úÖ Extracted {len(urls)} URLs\")\n",
    "    \n",
    "    # Show URL type distribution\n",
    "    url_types = {}\n",
    "    for url in urls:\n",
    "        url_type = url['url_type']\n",
    "        url_types[url_type] = url_types.get(url_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nüìä URL distribution by type:\")\n",
    "    for url_type, count in url_types.items():\n",
    "        print(f\"   {url_type}: {count}\")\n",
    "    \n",
    "    # Show sample URLs\n",
    "    print(\"\\nüìã Sample URLs to validate:\")\n",
    "    for i, url in enumerate(urls[:5]):\n",
    "        print(f\"   {i+1}. [{url['url_type']}] {url['topic_title'][:50]}...\")\n",
    "        print(f\"      URL: {url['url']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error extracting URLs: {e}\")\n",
    "    urls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Validation Tasks\n",
    "\n",
    "Create validation tasks for URLs that haven't been validated yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Creating validation tasks...\n",
      "üîÑ Task Creator Agent starting...\n",
      "üìã Loaded 260 URLs from urls_to_validate.json\n",
      "‚úÖ Created 260 validation tasks\n",
      "üíæ Saved tasks to validation_tasks.json\n",
      "\n",
      "üìä Task Summary:\n",
      "   Total tasks: 260\n",
      "   Tasks by type:\n",
      "     article: 62\n",
      "     paper: 26\n",
      "     video: 61\n",
      "     exercise: 65\n",
      "     python: 37\n",
      "     cpp: 9\n",
      "\n",
      "‚úÖ Created 260 validation tasks\n",
      "\n",
      "üìä Tasks by URL type:\n",
      "   article: 62\n",
      "   paper: 26\n",
      "   video: 61\n",
      "   exercise: 65\n",
      "   python: 37\n",
      "   cpp: 9\n"
     ]
    }
   ],
   "source": [
    "# Create validation tasks\n",
    "print(\"üìã Creating validation tasks...\")\n",
    "\n",
    "try:\n",
    "    task_creator = TaskCreatorAgent(CONFIG['urls_file'])\n",
    "    \n",
    "    # Run task creation\n",
    "    tasks = await task_creator.run()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Created {len(tasks)} validation tasks\")\n",
    "    \n",
    "    # Show task distribution\n",
    "    task_types = {}\n",
    "    for task in tasks:\n",
    "        url_type = task['url_entry']['url_type']\n",
    "        task_types[url_type] = task_types.get(url_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nüìä Tasks by URL type:\")\n",
    "    for url_type, count in task_types.items():\n",
    "        print(f\"   {url_type}: {count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating tasks: {e}\")\n",
    "    tasks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run URL Validation\n",
    "\n",
    "Run the multi-agent URL validation system. This will:\n",
    "- Check if URLs exist and are accessible\n",
    "- Analyze content to ensure appropriate targeting\n",
    "- Use AI to find replacements for broken/inappropriate URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting URL validation pipeline...\n",
      "   Using 2 consumer agents\n",
      "   Max 2 concurrent requests per agent\n",
      "   LM Studio URL: http://localhost:1234\n",
      "üöÄ Starting URL Validation Pipeline\n",
      "   Consumer agents: 2\n",
      "   Max concurrent requests per agent: 2\n",
      "   LM Studio URL: http://localhost:1234\n",
      "\n",
      "üìã Step 1: Creating validation tasks...\n",
      "üîÑ Task Creator Agent starting...\n",
      "üìã Loaded 260 URLs from urls_to_validate.json\n",
      "‚úÖ Created 260 validation tasks\n",
      "üíæ Saved tasks to validation_tasks.json\n",
      "\n",
      "üìä Task Summary:\n",
      "   Total tasks: 260\n",
      "   Tasks by type:\n",
      "     article: 62\n",
      "     paper: 26\n",
      "     video: 61\n",
      "     exercise: 65\n",
      "     python: 37\n",
      "     cpp: 9\n",
      "\n",
      "ü§ñ Step 2: Starting consumer agents...\n",
      "   üü¢ Agent agent_1 starting with 130 tasks\n",
      "   üü¢ Agent agent_2 starting with 130 tasks\n",
      "üîç Validating article URL: https://developer.nvidia.com/blog/even-easier-introduction-cuda/\n",
      "üîç Validating paper URL: https://dl.acm.org/doi/10.1145/1365490.1365500\n",
      "üîç Validating article URL: https://arxiv.org/abs/2205.05198\n",
      "üîç Validating video URL: https://www.youtube.com/watch?v=0QwZ9BtVu0E\n",
      "‚ùå URL does not exist: HTTP 403: Forbidden\n",
      "‚ùå No replacement found\n",
      "üîç Validating video URL: https://www.youtube.com/watch?v=-P28LKWTzrI\n",
      "‚ö†Ô∏è  URL exists but content inappropriate: \n",
      "‚ö†Ô∏è  URL exists but content inappropriate: \n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå No replacement found\n",
      "üîç Validating exercise URL: https://github.com/NVIDIA/Megatron-LM\n",
      "‚ùå No replacement found\n",
      "üîç Validating exercise URL: https://github.com/NVIDIA/Megatron-LM\n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚úÖ URL is valid and appropriate\n",
      "üîç Validating exercise URL: https://leetgpu.com/challenges\n",
      "‚ùå Error in LLM content analysis (attempt 3/3): \n",
      "‚úÖ URL is valid and appropriate\n",
      "üîç Validating article URL: https://cvw.cac.cornell.edu/gpu-architecture/gpu-characteristics/kernel_sm\n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå Error in LLM content analysis (attempt 3/3): \n",
      "‚ö†Ô∏è  URL exists but content inappropriate: Appears to be a listing/index page rather than specific content\n",
      "‚ùå Error in LLM content analysis (attempt 3/3): \n",
      "‚ö†Ô∏è  URL exists but content inappropriate: Appears to be a listing/index page rather than specific content\n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error calling LLM: \n",
      "‚ùå No replacement found\n",
      "üîç Validating exercise URL: https://leetgpu.com/challenges\n",
      "‚ùå No replacement found\n",
      "üîç Validating article URL: https://huggingface.co/blog/hello-hf-kernels\n",
      "‚ö†Ô∏è  URL exists but content inappropriate: \n",
      "‚úÖ URL is valid and appropriate\n",
      "üîç Validating paper URL: https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/NVIDIA-Kepler-GK110-Architecture-Whitepaper.pdf\n",
      "‚ùå URL does not exist: HTTP 404: Not Found\n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ö†Ô∏è  URL exists but content inappropriate: \n",
      "‚ùå Error calling LLM: \n",
      "‚ùå No replacement found\n",
      "üîç Validating video URL: https://www.youtube.com/watch?v=61aNaXjAqm0\n",
      "‚ùå No replacement found\n",
      "üîç Validating exercise URL: https://leetgpu.com/challenges\n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error calling LLM: \n",
      "‚ùå No replacement found\n",
      "üîç Validating exercise URL: https://github.com/huggingface/hf-kernels\n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå Error in LLM content analysis (attempt 3/3): \n",
      "‚úÖ URL is valid and appropriate\n",
      "üîç Validating article URL: https://arxiv.org/abs/2006.11239\n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ùå Error in LLM content analysis (attempt 1/3): \n",
      "‚ùå Error in LLM content analysis (attempt 2/3): \n",
      "‚ö†Ô∏è  Agent agent_1 task processing was cancelled, waiting for ongoing tasks to complete...\n",
      "‚ö†Ô∏è  Agent agent_1 was cancelled, attempting to save partial results...\n",
      "‚ö†Ô∏è  URL exists but content inappropriate: \n",
      "‚ùå No replacement found\n",
      "‚ö†Ô∏è  Agent agent_2 task processing was cancelled, waiting for ongoing tasks to complete...\n",
      "‚ö†Ô∏è  Agent agent_2 was cancelled, attempting to save partial results...\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Run validation pipeline\u001b[39;00m\n\u001b[32m     17\u001b[39m start_time = datetime.now()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m summary = \u001b[38;5;28;01mawait\u001b[39;00m orchestrator.run_validation_pipeline()\n\u001b[32m     19\u001b[39m end_time = datetime.now()\n\u001b[32m     21\u001b[39m duration = end_time - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/gpu-programming-ladder/url_validator/url_validation_orchestrator.py:62\u001b[39m, in \u001b[36mURLValidationOrchestrator.run_validation_pipeline\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# Step 2: Distribute tasks to consumer agents\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mü§ñ Step 2: Starting consumer agents...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_consumer_agents(tasks)\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# Step 3: Save results\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müíæ Step 3: Saving validation results...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/gpu-programming-ladder/url_validator/url_validation_orchestrator.py:100\u001b[39m, in \u001b[36mURLValidationOrchestrator._run_consumer_agents\u001b[39m\u001b[34m(self, tasks)\u001b[39m\n\u001b[32m     96\u001b[39m     agent_coroutines.append(coroutine)\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# Use return_exceptions=True to prevent cancellation propagation\u001b[39;00m\n\u001b[32m     99\u001b[39m \u001b[38;5;66;03m# This ensures that if one agent fails or gets cancelled, others continue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m agent_results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*agent_coroutines, return_exceptions=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Handle any exceptions that occurred\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(agent_results):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/gpu-programming-ladder/url_validator/url_validation_orchestrator.py:126\u001b[39m, in \u001b[36mURLValidationOrchestrator._run_single_agent\u001b[39m\u001b[34m(self, agent_id, tasks)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m URLValidatorAgent(\n\u001b[32m    121\u001b[39m         agent_id=agent_id,\n\u001b[32m    122\u001b[39m         lm_studio_url=\u001b[38;5;28mself\u001b[39m.lm_studio_url,\n\u001b[32m    123\u001b[39m         max_concurrent_requests=\u001b[38;5;28mself\u001b[39m.max_concurrent_requests_per_agent\n\u001b[32m    124\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m agent:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         processed_tasks = \u001b[38;5;28;01mawait\u001b[39;00m agent.process_tasks(tasks)\n\u001b[32m    128\u001b[39m         \u001b[38;5;66;03m# Thread-safe update of completed tasks\u001b[39;00m\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/gpu-programming-ladder/url_validator/url_validator_agent.py:598\u001b[39m, in \u001b[36mprocess_tasks\u001b[39m\u001b[34m(self, tasks)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/gpu-programming-ladder/url_validator/url_validator_agent.py:570\u001b[39m, in \u001b[36mprocess_task_with_semaphore\u001b[39m\u001b[34m(task)\u001b[39m\n\u001b[32m    568\u001b[39m         print(f\"‚ö†Ô∏è  Selected LeetGPU exercise URL is invalid: {error}\")\n\u001b[32m    569\u001b[39m         return None\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m else:\n\u001b[32m    571\u001b[39m     print(\"‚ùå No suitable LeetGPU exercise found for this topic\")\n\u001b[32m    572\u001b[39m     return None\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.14/asyncio/locks.py:14\u001b[39m, in \u001b[36m_ContextManagerMixin.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.acquire()\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# We have no use for the \"as ...\"  clause in the with\u001b[39;00m\n\u001b[32m     16\u001b[39m     \u001b[38;5;66;03m# statement for locks.\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.14/asyncio/locks.py:407\u001b[39m, in \u001b[36mSemaphore.acquire\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    406\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    408\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    409\u001b[39m         \u001b[38;5;28mself\u001b[39m._waiters.remove(fut)\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run URL validation with orchestrator\n",
    "print(\"üöÄ Starting URL validation pipeline...\")\n",
    "print(f\"   Using {CONFIG['num_consumer_agents']} consumer agents\")\n",
    "print(f\"   Max {CONFIG['max_concurrent_requests_per_agent']} concurrent requests per agent\")\n",
    "print(f\"   LM Studio URL: {CONFIG['lm_studio_url']}\")\n",
    "\n",
    "try:\n",
    "    orchestrator = URLValidationOrchestrator(\n",
    "        num_consumer_agents=CONFIG['num_consumer_agents'],\n",
    "        max_concurrent_requests_per_agent=CONFIG['max_concurrent_requests_per_agent'],\n",
    "        lm_studio_url=CONFIG['lm_studio_url'],\n",
    "        tasks_file=CONFIG['tasks_file'],\n",
    "        results_file=CONFIG['results_file']\n",
    "    )\n",
    "    \n",
    "    # Run validation pipeline\n",
    "    start_time = datetime.now()\n",
    "    summary = await orchestrator.run_validation_pipeline()\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    print(f\"\\n‚è±Ô∏è  Validation completed in {duration.total_seconds():.1f} seconds\")\n",
    "    \n",
    "    # Add timing information to summary for enhanced reporting\n",
    "    if 'error' not in summary:\n",
    "        summary['total_duration_seconds'] = duration.total_seconds()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during validation: {e}\")\n",
    "    summary = {'error': str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Review Validation Results\n",
    "\n",
    "Review the validation results and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display validation summary\n",
    "if 'error' not in summary:\n",
    "    print(\"üìä Validation Summary:\")\n",
    "    print(f\"   Total URLs processed: {summary['total_urls_processed']}\")\n",
    "    print(f\"   Valid URLs: {summary['valid_urls']}\")\n",
    "    print(f\"   Invalid URLs: {summary['invalid_urls']}\")\n",
    "    print(f\"   URLs with replacements: {summary['replaced_urls']}\")\n",
    "    print(f\"   URLs to be removed: {summary['removed_urls']}\")\n",
    "    print(f\"   Success rate: {summary['success_rate']:.1f}%\")\n",
    "    \n",
    "    # Time-related statistics\n",
    "    if 'total_duration_seconds' in summary and summary['total_urls_processed'] > 0:\n",
    "        avg_time_per_url = summary['total_duration_seconds'] / summary['total_urls_processed']\n",
    "        urls_per_minute = (summary['total_urls_processed'] / summary['total_duration_seconds']) * 60\n",
    "        \n",
    "        print(\"\\n‚è±Ô∏è  Performance Statistics:\")\n",
    "        print(f\"   Total processing time: {summary['total_duration_seconds']:.1f} seconds\")\n",
    "        print(f\"   Average time per URL: {avg_time_per_url:.2f} seconds\")\n",
    "        print(f\"   Processing rate: {urls_per_minute:.1f} URLs/minute\")\n",
    "        \n",
    "        # Phase breakdown if available\n",
    "        if 'phase_durations' in summary:\n",
    "            phases = summary['phase_durations']\n",
    "            print(\"\\nüìà Time Breakdown by Phase:\")\n",
    "            for phase, duration in phases.items():\n",
    "                percentage = (duration / summary['total_duration_seconds']) * 100\n",
    "                print(f\"   {phase}: {duration:.1f}s ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüìã Breakdown by URL type:\")\n",
    "    for url_type, stats in summary['urls_by_type'].items():\n",
    "        total = stats['total']\n",
    "        valid = stats['valid']\n",
    "        replaced = stats['replaced']\n",
    "        removed = stats['invalid'] - stats['replaced']\n",
    "        \n",
    "        # Time stats per URL type if available\n",
    "        type_stats = f\"{url_type}: {valid}/{total} valid, {replaced} replaced, {removed} to remove\"\n",
    "        if 'avg_time_per_url' in stats:\n",
    "            type_stats += f\" (avg: {stats['avg_time_per_url']:.2f}s/URL)\"\n",
    "        print(f\"   {type_stats}\")\n",
    "        \n",
    "    # Show agent performance if available\n",
    "    if 'agent_performance' in summary:\n",
    "        print(\"\\nü§ñ Agent Performance:\")\n",
    "        for agent_id, perf in summary['agent_performance'].items():\n",
    "            urls_processed = perf.get('urls_processed', 0)\n",
    "            time_spent = perf.get('time_spent', 0)\n",
    "            avg_time = time_spent / urls_processed if urls_processed > 0 else 0\n",
    "            print(f\"   Agent {agent_id}: {urls_processed} URLs, {time_spent:.1f}s total, {avg_time:.2f}s/URL\")\n",
    "else:\n",
    "    print(f\"‚ùå Validation failed: {summary['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Update data.js File (Optional)\n",
    "\n",
    "Update the original data.js file with the validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update data.js with validation results\n",
    "if CONFIG['update_data_js'] and 'error' not in summary:\n",
    "    print(\"üîÑ Updating data.js with validation results...\")\n",
    "    \n",
    "    try:\n",
    "        success = await orchestrator.update_data_js_with_results(CONFIG['data_js_file'])\n",
    "        if success:\n",
    "            print(\"‚úÖ data.js updated successfully\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to update data.js\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error updating data.js: {e}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping data.js update\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP Tools Configuration\n",
    "\n",
    "To configure MCP (Model Context Protocol) tools for enhanced functionality:\n",
    "\n",
    "### Available MCP Tools\n",
    "1. **firecrawl**: Web scraping and content extraction\n",
    "2. **context7**: Library documentation search\n",
    "3. **brave-search**: Web search capabilities\n",
    "\n",
    "### Configuration Steps\n",
    "1. Install MCP server packages\n",
    "2. Configure MCP client in your LLM setup\n",
    "3. Update the `find_replacement_url` method to use MCP tools\n",
    "\n",
    "### Example MCP Integration\n",
    "```python\n",
    "# Add to URLValidatorAgent.__init__\n",
    "self.mcp_client = MCPClient(\n",
    "    server_configs={\n",
    "        'firecrawl': {'url': 'http://localhost:3000'},\n",
    "        'context7': {'url': 'http://localhost:3001'}\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use in find_replacement_url method\n",
    "search_results = await self.mcp_client.search('brave-search', query)\n",
    "scraped_content = await self.mcp_client.scrape('firecrawl', url)\n",
    "```\n",
    "\n",
    "### Benefits of MCP Integration\n",
    "- **Enhanced search**: Use Brave Search for finding replacements\n",
    "- **Better scraping**: Use Firecrawl for content validation\n",
    "- **Documentation lookup**: Use Context7 for library-specific resources\n",
    "- **Fallback mechanisms**: Multiple tools for robust URL finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**LM Studio Connection Issues**\n",
    "```bash\n",
    "# Check LM Studio status\n",
    "curl http://localhost:1234/v1/models\n",
    "\n",
    "# Verify model is loaded\n",
    "# Restart LM Studio if needed\n",
    "```\n",
    "\n",
    "**Rate Limiting**\n",
    "```json\n",
    "// Reduce concurrent requests in config.json\n",
    "{\n",
    "  \"agents\": {\n",
    "    \"max_concurrent_requests_per_agent\": 3\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Memory Issues**\n",
    "```json\n",
    "// Process in smaller batches\n",
    "{\n",
    "  \"processing\": {\n",
    "    \"batch_size\": 25\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**URL Validation Issues**\n",
    "- Some sites block automated requests - consider using proxies\n",
    "- PDFs and binary content may not be properly analyzed\n",
    "- GitHub rate limiting may affect repository checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After running this validation system:\n",
    "\n",
    "1. **Review changes**: Check the updated data.js file\n",
    "2. **Manual verification**: Spot-check some URLs to ensure replacements are appropriate\n",
    "3. **Re-run periodically**: URLs can break over time, so re-validation is recommended\n",
    "4. **Extend functionality**: Add more URL types or validation rules as needed\n",
    "\n",
    "### Potential Enhancements\n",
    "- **Content freshness checking**: Verify that content is still relevant\n",
    "- **Duplicate detection**: Find and remove duplicate URLs\n",
    "- **Quality scoring**: Rate URLs by content quality\n",
    "- **Automated scheduling**: Set up regular validation runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
