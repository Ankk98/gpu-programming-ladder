{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Programming Ladder URL Validation System\n",
    "\n",
    "This notebook orchestrates an AI agent system to validate and update URLs in the GPU Programming Ladder data.\n",
    "\n",
    "## Features\n",
    "- **Multi-agent system**: Task creator agent + multiple consumer agents\n",
    "- **URL validation**: Checks if URLs exist and are accessible\n",
    "- **Content analysis**: Ensures exercise/video URLs point to specific content, not listings\n",
    "- **AI-powered replacements**: Uses local LLM (GPT-4o via LM Studio) to find replacements\n",
    "- **Parallel processing**: Configurable concurrent requests with rate limiting\n",
    "- **Thread safety**: No race conditions in concurrent operations\n",
    "\n",
    "## Requirements\n",
    "- Python 3.8+\n",
    "- LM Studio running locally with GPT-4o model\n",
    "- Required Python packages (installed in virtual environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import sys\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Add current directory to path for imports\n",
    "sys.path.append('.')\n",
    "\n",
    "# Import our custom modules\n",
    "from url_validation_orchestrator import URLValidationOrchestrator\n",
    "from url_extractor import extract_urls_from_data_js\n",
    "from task_creator_agent import TaskCreatorAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Configure the validation system parameters below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Configuration\n",
    "CONFIG = {\n",
    "    # LM Studio configuration\n",
    "    'lm_studio_url': 'http://localhost:1234',  # Update if LM Studio runs on different port\n",
    "    \n",
    "    # Agent configuration\n",
    "    'num_consumer_agents': 3,  # Number of parallel consumer agents\n",
    "    'max_concurrent_requests_per_agent': 5,  # Concurrent requests per agent (rate limiting)\n",
    "    \n",
    "    # File paths\n",
    "    'data_js_file': '../data.js',\n",
    "    'urls_file': '../urls_to_validate.json',\n",
    "    'tasks_file': '../validation_tasks.json',\n",
    "    'results_file': '../validation_results.json',\n",
    "    \n",
    "    # Processing options\n",
    "    'update_data_js': True,  # Whether to update the original data.js file\n",
    "    'force_revalidation': False  # Set to True to revalidate all URLs\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Extract URLs from data.js\n",
    "\n",
    "First, let's extract all URLs from the data.js file that need validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract URLs from data.js\n",
    "print(\"üîç Extracting URLs from data.js...\")\n",
    "\n",
    "try:\n",
    "    urls = extract_urls_from_data_js(CONFIG['data_js_file'])\n",
    "    print(f\"‚úÖ Extracted {len(urls)} URLs\")\n",
    "    \n",
    "    # Show URL type distribution\n",
    "    url_types = {}\n",
    "    for url in urls:\n",
    "        url_type = url['url_type']\n",
    "        url_types[url_type] = url_types.get(url_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nüìä URL distribution by type:\")\n",
    "    for url_type, count in url_types.items():\n",
    "        print(f\"   {url_type}: {count}\")\n",
    "    \n",
    "    # Show sample URLs\n",
    "    print(\"\\nüìã Sample URLs to validate:\")\n",
    "    for i, url in enumerate(urls[:5]):\n",
    "        print(f\"   {i+1}. [{url['url_type']}] {url['topic_title'][:50]}...\")\n",
    "        print(f\"      URL: {url['url']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error extracting URLs: {e}\")\n",
    "    urls = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Validation Tasks\n",
    "\n",
    "Create validation tasks for URLs that haven't been validated yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation tasks\n",
    "print(\"üìã Creating validation tasks...\")\n",
    "\n",
    "try:\n",
    "    task_creator = TaskCreatorAgent(CONFIG['urls_file'])\n",
    "    \n",
    "    # Run task creation\n",
    "    tasks = await task_creator.run()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Created {len(tasks)} validation tasks\")\n",
    "    \n",
    "    # Show task distribution\n",
    "    task_types = {}\n",
    "    for task in tasks:\n",
    "        url_type = task['url_entry']['url_type']\n",
    "        task_types[url_type] = task_types.get(url_type, 0) + 1\n",
    "    \n",
    "    print(\"\\nüìä Tasks by URL type:\")\n",
    "    for url_type, count in task_types.items():\n",
    "        print(f\"   {url_type}: {count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating tasks: {e}\")\n",
    "    tasks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Run URL Validation\n",
    "\n",
    "Run the multi-agent URL validation system. This will:\n",
    "- Check if URLs exist and are accessible\n",
    "- Analyze content to ensure appropriate targeting\n",
    "- Use AI to find replacements for broken/inappropriate URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run URL validation with orchestrator\n",
    "print(\"üöÄ Starting URL validation pipeline...\")\n",
    "print(f\"   Using {CONFIG['num_consumer_agents']} consumer agents\")\n",
    "print(f\"   Max {CONFIG['max_concurrent_requests_per_agent']} concurrent requests per agent\")\n",
    "print(f\"   LM Studio URL: {CONFIG['lm_studio_url']}\")\n",
    "\n",
    "try:\n",
    "    orchestrator = URLValidationOrchestrator(\n",
    "        num_consumer_agents=CONFIG['num_consumer_agents'],\n",
    "        max_concurrent_requests_per_agent=CONFIG['max_concurrent_requests_per_agent'],\n",
    "        lm_studio_url=CONFIG['lm_studio_url'],\n",
    "        tasks_file=CONFIG['tasks_file'],\n",
    "        results_file=CONFIG['results_file']\n",
    "    )\n",
    "    \n",
    "    # Run validation pipeline\n",
    "    start_time = datetime.now()\n",
    "    summary = await orchestrator.run_validation_pipeline()\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    duration = end_time - start_time\n",
    "    print(f\"\\n‚è±Ô∏è  Validation completed in {duration.total_seconds():.1f} seconds\")\n",
    "    \n",
    "    # Add timing information to summary for enhanced reporting\n",
    "    if 'error' not in summary:\n",
    "        summary['total_duration_seconds'] = duration.total_seconds()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error during validation: {e}\")\n",
    "    summary = {'error': str(e)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Review Validation Results\n",
    "\n",
    "Review the validation results and summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display validation summary\n",
    "if 'error' not in summary:\n",
    "    print(\"üìä Validation Summary:\")\n",
    "    print(f\"   Total URLs processed: {summary['total_urls_processed']}\")\n",
    "    print(f\"   Valid URLs: {summary['valid_urls']}\")\n",
    "    print(f\"   Invalid URLs: {summary['invalid_urls']}\")\n",
    "    print(f\"   URLs with replacements: {summary['replaced_urls']}\")\n",
    "    print(f\"   URLs to be removed: {summary['removed_urls']}\")\n",
    "    print(f\"   Success rate: {summary['success_rate']:.1f}%\")\n",
    "    \n",
    "    # Time-related statistics\n",
    "    if 'total_duration_seconds' in summary and summary['total_urls_processed'] > 0:\n",
    "        avg_time_per_url = summary['total_duration_seconds'] / summary['total_urls_processed']\n",
    "        urls_per_minute = (summary['total_urls_processed'] / summary['total_duration_seconds']) * 60\n",
    "        \n",
    "        print(\"\\n‚è±Ô∏è  Performance Statistics:\")\n",
    "        print(f\"   Total processing time: {summary['total_duration_seconds']:.1f} seconds\")\n",
    "        print(f\"   Average time per URL: {avg_time_per_url:.2f} seconds\")\n",
    "        print(f\"   Processing rate: {urls_per_minute:.1f} URLs/minute\")\n",
    "        \n",
    "        # Phase breakdown if available\n",
    "        if 'phase_durations' in summary:\n",
    "            phases = summary['phase_durations']\n",
    "            print(\"\\nüìà Time Breakdown by Phase:\")\n",
    "            for phase, duration in phases.items():\n",
    "                percentage = (duration / summary['total_duration_seconds']) * 100\n",
    "                print(f\"   {phase}: {duration:.1f}s ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüìã Breakdown by URL type:\")\n",
    "    for url_type, stats in summary['urls_by_type'].items():\n",
    "        total = stats['total']\n",
    "        valid = stats['valid']\n",
    "        replaced = stats['replaced']\n",
    "        removed = stats['invalid'] - stats['replaced']\n",
    "        \n",
    "        # Time stats per URL type if available\n",
    "        type_stats = f\"{url_type}: {valid}/{total} valid, {replaced} replaced, {removed} to remove\"\n",
    "        if 'avg_time_per_url' in stats:\n",
    "            type_stats += f\" (avg: {stats['avg_time_per_url']:.2f}s/URL)\"\n",
    "        print(f\"   {type_stats}\")\n",
    "        \n",
    "    # Show agent performance if available\n",
    "    if 'agent_performance' in summary:\n",
    "        print(\"\\nü§ñ Agent Performance:\")\n",
    "        for agent_id, perf in summary['agent_performance'].items():\n",
    "            urls_processed = perf.get('urls_processed', 0)\n",
    "            time_spent = perf.get('time_spent', 0)\n",
    "            avg_time = time_spent / urls_processed if urls_processed > 0 else 0\n",
    "            print(f\"   Agent {agent_id}: {urls_processed} URLs, {time_spent:.1f}s total, {avg_time:.2f}s/URL\")\n",
    "else:\n",
    "    print(f\"‚ùå Validation failed: {summary['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Update data.js File (Optional)\n",
    "\n",
    "Update the original data.js file with the validation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update data.js with validation results\n",
    "if CONFIG['update_data_js'] and 'error' not in summary:\n",
    "    print(\"üîÑ Updating data.js with validation results...\")\n",
    "    \n",
    "    try:\n",
    "        success = await orchestrator.update_data_js_with_results(CONFIG['data_js_file'])\n",
    "        if success:\n",
    "            print(\"‚úÖ data.js updated successfully\")\n",
    "        else:\n",
    "            print(\"‚ùå Failed to update data.js\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error updating data.js: {e}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping data.js update\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP Tools Configuration\n",
    "\n",
    "To configure MCP (Model Context Protocol) tools for enhanced functionality:\n",
    "\n",
    "### Available MCP Tools\n",
    "1. **firecrawl**: Web scraping and content extraction\n",
    "2. **context7**: Library documentation search\n",
    "3. **brave-search**: Web search capabilities\n",
    "\n",
    "### Configuration Steps\n",
    "1. Install MCP server packages\n",
    "2. Configure MCP client in your LLM setup\n",
    "3. Update the `find_replacement_url` method to use MCP tools\n",
    "\n",
    "### Example MCP Integration\n",
    "```python\n",
    "# Add to URLValidatorAgent.__init__\n",
    "self.mcp_client = MCPClient(\n",
    "    server_configs={\n",
    "        'firecrawl': {'url': 'http://localhost:3000'},\n",
    "        'context7': {'url': 'http://localhost:3001'}\n",
    "    }\n",
    ")\n",
    "\n",
    "# Use in find_replacement_url method\n",
    "search_results = await self.mcp_client.search('brave-search', query)\n",
    "scraped_content = await self.mcp_client.scrape('firecrawl', url)\n",
    "```\n",
    "\n",
    "### Benefits of MCP Integration\n",
    "- **Enhanced search**: Use Brave Search for finding replacements\n",
    "- **Better scraping**: Use Firecrawl for content validation\n",
    "- **Documentation lookup**: Use Context7 for library-specific resources\n",
    "- **Fallback mechanisms**: Multiple tools for robust URL finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Common Issues\n",
    "\n",
    "**LM Studio Connection Issues**\n",
    "```bash\n",
    "# Check LM Studio status\n",
    "curl http://localhost:1234/v1/models\n",
    "\n",
    "# Verify model is loaded\n",
    "# Restart LM Studio if needed\n",
    "```\n",
    "\n",
    "**Rate Limiting**\n",
    "```json\n",
    "// Reduce concurrent requests in config.json\n",
    "{\n",
    "  \"agents\": {\n",
    "    \"max_concurrent_requests_per_agent\": 3\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Memory Issues**\n",
    "```json\n",
    "// Process in smaller batches\n",
    "{\n",
    "  \"processing\": {\n",
    "    \"batch_size\": 25\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**URL Validation Issues**\n",
    "- Some sites block automated requests - consider using proxies\n",
    "- PDFs and binary content may not be properly analyzed\n",
    "- GitHub rate limiting may affect repository checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After running this validation system:\n",
    "\n",
    "1. **Review changes**: Check the updated data.js file\n",
    "2. **Manual verification**: Spot-check some URLs to ensure replacements are appropriate\n",
    "3. **Re-run periodically**: URLs can break over time, so re-validation is recommended\n",
    "4. **Extend functionality**: Add more URL types or validation rules as needed\n",
    "\n",
    "### Potential Enhancements\n",
    "- **Content freshness checking**: Verify that content is still relevant\n",
    "- **Duplicate detection**: Find and remove duplicate URLs\n",
    "- **Quality scoring**: Rate URLs by content quality\n",
    "- **Automated scheduling**: Set up regular validation runs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_ladder_env",
   "language": "python",
   "name": "gpu_ladder_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
